# Cost Metrics Schema
# Defines the fields and structure used to track token usage and compute cost estimates per prompt run.

cost_metrics_schema:
  version: "1.0"
  description: |
    Standard format for measuring and logging cost-related data for LLM prompt runs.
    Includes token counts, model rates, and dynamic cost overrides.

  fields:
    prompt_id:
      type: string
      description: Unique name or ID for the prompt version.
    model:
      type: string
      description: Model used (e.g., gpt-4, claude-3, llama-3).
    tokens_input:
      type: integer
      description: Number of input tokens sent to the model.
    tokens_output:
      type: integer
      description: Number of output tokens generated by the model.
    cost_per_1k_input:
      type: number
      description: Cost in USD per 1,000 input tokens for the model used.
    cost_per_1k_output:
      type: number
      description: Cost in USD per 1,000 output tokens for the model used.
    total_cost_usd:
      type: number
      description: Total calculated cost for this run in USD.
    region:
      type: string
      optional: true
      description: Optional regional override (e.g., "us-east-1", "eu-west-2").
    usage_context:
      type: string
      optional: true
      description: Optional context tag for grouping (e.g., "batch-job", "agent-verifier").
    timestamp:
      type: string
      format: iso8601
      description: When the run occurred (UTC).

  example:
    prompt_id: "rag-qa-v2"
    model: "gpt-4"
    tokens_input: 425
    tokens_output: 312
    cost_per_1k_input: 0.03
    cost_per_1k_output: 0.06
    total_cost_usd: 0.04566
    region: "us-east-1"
    usage_context: "support-agent"
    timestamp: "2025-07-01T20:12:00Z"
