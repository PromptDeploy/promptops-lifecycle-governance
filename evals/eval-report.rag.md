# ðŸ“Š PromptOps Eval Report: RAG Fallback Behavior

## Summary

| Model         | Tests Run | Passed | Failed | Pass Rate |
| ------------- | --------- | ------ | ------ | --------- |
| GPT-4o        | 2         | 2      | 0      | âœ… 100%   |
| Claude 3 Opus | 2         | 1      | 1      | âš ï¸ 50%    |

---

## Detailed Results

### ðŸ”¹ GPT-4o

**Test:** RAG fallback: missing context  
âœ… _Includes â€œdonâ€™t have enough informationâ€_  
âœ… _Did not include hallucinated content_

**Test:** RAG fallback: weak context  
âœ… _Includes â€œwerenâ€™t foundâ€_  
âœ… _Did not include â€œreset passwordâ€_

---

### ðŸ”¸ Claude 3 Opus

**Test:** RAG fallback: missing context  
âš ï¸ _Response included speculative answer despite missing context_  
âŒ _Failed includes check: â€œdonâ€™t have enough informationâ€ not found_  
âœ… _No hallucinated terms detected_

**Test:** RAG fallback: weak context  
âœ… _Includes â€œwerenâ€™t foundâ€_  
âœ… _Passed all assertions_

---

## Insights

- GPT-4o is more conservative with missing context and better avoids unsupported answers.
- Claude 3 may need additional grounding logic or stricter fallback instructions in prompt.

> ðŸ§ª Consider extending test cases to include partial context, adversarial phrasing, or malicious prompt injection attempts.
